This report presents a deep learning-based system for speech emotion recognition. The goal is to classify seven emotions (e.g., happy, sad, surprise, etc.) from speech signals with high accuracy. Our approach includes data preprocessing, feature extraction (e.g., MFCC and ZCR), and model training using convolutional neural networks (CNNs). We utilized several publicly available datasets for experimentation and applied data augmentation techniques to enhance model generalizability. Several publicly available datasets, such as RAVDESS, CREMA-D, TESS, and SAVEE, were used for training and evaluation. Data augmentation techniques, including noise addition and pitch shifting, were employed to enhance generalization.
